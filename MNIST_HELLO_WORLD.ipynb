{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_HELLO_WORLD.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BraneXZ/CNN_Cifar10_with_InceptionV4/blob/master/MNIST_HELLO_WORLD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baUYjQhL97Ck",
        "colab_type": "code",
        "outputId": "d56a0111-ebcd-43cc-82c1-d4ea3c71580d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from   tensorflow import keras\n",
        "import math\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr-3iq4--TWx",
        "colab_type": "code",
        "outputId": "1b721324-6c45-4adf-fda1-74567a12b172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czqS-KKW-Ttb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train,info = tfds.load('mnist', split='train', data_dir=\"/content/drive/My Drive\", with_info=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gAwuArz-eQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = tfds.load('mnist', split='test', data_dir=\"/content/drive/My Drive\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxRHonzu-3lX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  model_input = keras.Input(shape=(28, 28, 1), name='input_image')\n",
        "  x = model_input\n",
        "#   x = keras.layers.Flatten()(model_input)\n",
        "  x = keras.layers.Dense(3, activation='relu')(x)\n",
        "  for i in range(2):\n",
        "    x = keras.layers.Conv2D(32, 3, strides=1, padding='same', activation=None, use_bias=False)(x)\n",
        "    x = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True)(x)\n",
        "    x = keras.layers.ReLU()(x)\n",
        "  x = keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "  \n",
        "  encoder_output = x\n",
        "  \n",
        "  y              = keras.layers.GlobalAveragePooling2D()(encoder_output)\n",
        "  decoder_output = keras.layers.Dense(10, activation='softmax')(y)\n",
        "  \n",
        "  model = keras.Model(inputs=model_input, outputs=decoder_output, name='mnist_model')\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGB-tGcAA7xY",
        "colab_type": "code",
        "outputId": "911d6166-73dd-4e23-bf99-4a02aeccd4b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "model = create_model()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_image (InputLayer)     [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 28, 28, 32)        288       \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "re_lu_10 (ReLU)              (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 28, 28, 32)        9216      \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "re_lu_11 (ReLU)              (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_5 ( (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 10,090\n",
            "Trainable params: 9,962\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mzdo2SWUBImE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_train(x):\n",
        "  image = x['image']\n",
        "  label = x['label']\n",
        "  \n",
        "  image = tf.math.divide(tf.dtypes.cast(image, tf.float32), 255)\n",
        "  label = tf.dtypes.cast(label, tf.int32)\n",
        "\n",
        "  return image, label\n",
        "\n",
        "def preprocess_test(x):\n",
        "  image = x['image']\n",
        "  label = x['label']\n",
        "  \n",
        "  image = tf.math.divide(tf.dtypes.cast(image, tf.float32), 255)\n",
        "  label = tf.dtypes.cast(label, tf.int32)\n",
        "\n",
        "  return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-nbTW2TBdNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.map(preprocess_train, 4)\n",
        "test = test.map(preprocess_test, 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKkHV7I7HdkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.batch(32)\n",
        "test = test.batch(32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HFqmO2LIh9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.prefetch(1)\n",
        "test = test.prefetch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3LTvtSFIy74",
        "colab_type": "code",
        "outputId": "04ce738f-e70a-49b0-b7f2-9b04cf21d535",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: ((?, 28, 28, 1), (?,)), types: (tf.float32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCNQfqigKpm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEVjz3Y5BlZs",
        "colab_type": "code",
        "outputId": "e6cd51ee-7268-4592-da94-e7c32c35521f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "history = model.fit(train, epochs=10, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 211s 113ms/step - loss: 1.2430 - acc: 0.6707\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 215s 114ms/step - loss: 0.6593 - acc: 0.8354\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 213s 114ms/step - loss: 0.4736 - acc: 0.8782\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 211s 112ms/step - loss: 0.3834 - acc: 0.8993\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 211s 113ms/step - loss: 0.3290 - acc: 0.9121\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 213s 113ms/step - loss: 0.2917 - acc: 0.9214\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 213s 114ms/step - loss: 0.2640 - acc: 0.9281\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 212s 113ms/step - loss: 0.2432 - acc: 0.9332\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 211s 113ms/step - loss: 0.2272 - acc: 0.9374\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 212s 113ms/step - loss: 0.2130 - acc: 0.9414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpPRLjVNBl89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot training accuracy and loss curves\n",
        "def plot_training_curves(history):\n",
        "\n",
        "    # training and validation data accuracy\n",
        "    acc     = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "\n",
        "    # training and validation data loss\n",
        "    loss     = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    # plot accuracy\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(acc, label='Training Accuracy')\n",
        "    plt.plot(val_acc, label='Validation Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.ylim([min(plt.ylim()), 1])\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    # plot loss\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(loss, label='Training Loss')\n",
        "    plt.plot(val_loss, label='Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.ylabel('Cross Entropy')\n",
        "    plt.ylim([0, 0.25])\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytIBtN8DHDbh",
        "colab_type": "code",
        "outputId": "1f106b38-6d91-4847-a7b4-cbdfc13b10ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "plot_training_curves(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-acbdcf8bcd99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_training_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-6752c225481e>\u001b[0m in \u001b[0;36mplot_training_curves\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# training and validation data accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0macc\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3wuDfvcHFWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}